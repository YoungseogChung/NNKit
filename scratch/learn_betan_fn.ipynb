{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from nn_model import vanilla_nn\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_npy_dir = './disrupt_630_npy'\n",
    "nondis_npy_dir = './nondisrupt_1136_npy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_header = np.load(os.path.join(dis_npy_dir, 'header_arr.npy'))\n",
    "nondis_header = np.load(os.path.join(nondis_npy_dir, 'header_arr.npy'))\n",
    "dis_time = np.load(os.path.join(dis_npy_dir, 'time_arr.npy'))\n",
    "nondis_time = np.load(os.path.join(nondis_npy_dir, 'time_arr.npy'))\n",
    "\n",
    "print((dis_header.astype(str) == nondis_header.astype(str)).all())\n",
    "print((dis_time==nondis_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide final time index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_time = -150\n",
    "for time_idx in range(dis_time.shape[0]):\n",
    "    if dis_time[time_idx] > final_time:\n",
    "        final_time_idx = time_idx - 1\n",
    "        break\n",
    "print(final_time_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide signals to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_list = dis_header.astype(str).tolist()\n",
    "pprint(signal_list)\n",
    "use_signal = ['ip', 'efsbetan','efsli', 'efsvolume', 'pinj']\n",
    "use_signal_idx = [signal_list.index(x) for x in use_signal]\n",
    "num_state = 4\n",
    "num_action = 1\n",
    "print(len(signal_list))\n",
    "print(use_signal_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dis_arrs = []\n",
    "for item in os.listdir(dis_npy_dir):\n",
    "    if 'header' in item or 'time' in item:\n",
    "        continue\n",
    "    arr = np.load(os.path.join(dis_npy_dir, item))\n",
    "    try:\n",
    "        filtered_arr = arr[use_signal_idx, :final_time_idx]\n",
    "        if np.isnan(filtered_arr).any():\n",
    "            print('{} has nans'.format(item))\n",
    "            continue\n",
    "        dis_arrs.append(filtered_arr)\n",
    "    except:\n",
    "        print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dis_shots = len(dis_arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dis_arr = np.array(dis_arrs)\n",
    "print(full_dis_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the dataset by scanning through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_interval = 250\n",
    "total_timesteps = full_dis_arr.shape[-1]\n",
    "print(total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10).reshape(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['ip', 'efsbetan','efsli', 'efsvolume', 'pinj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "actions = []\n",
    "rewards = []\n",
    "sa_pairs = []\n",
    "\n",
    "for start_time_idx in range(total_timesteps):\n",
    "    start_time = dis_time[start_time_idx]\n",
    "    # find end time idx\n",
    "    end_time_idx = None\n",
    "    for temp_time_idx in range(dis_time.shape[0]):\n",
    "        if dis_time[temp_time_idx] > start_time + pred_interval:\n",
    "            end_time_idx = temp_time_idx\n",
    "            break\n",
    "    \n",
    "    # stop if beyond current data time range\n",
    "    if end_time_idx >= total_timesteps:\n",
    "        break\n",
    "    \n",
    "    curr_state = full_dis_arr[:,:-1,start_time_idx]\n",
    "    curr_action = np.mean(full_dis_arr[:,-1,start_time_idx:end_time_idx], axis=1).reshape(-1,1)\n",
    "    curr_reward = full_dis_arr[:,1,end_time_idx]\n",
    "    curr_sa = np.concatenate([curr_state, curr_action], axis=1)\n",
    "    \n",
    "    states.append(curr_state)\n",
    "    actions.append(curr_action)\n",
    "    rewards.append(curr_reward)\n",
    "    sa_pairs.append(curr_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prop = 0.8\n",
    "num_train_shots = int(num_dis_shots * train_prop)\n",
    "train_shot_idx = np.random.choice(num_dis_shots, \n",
    "                                  size=num_train_shots,\n",
    "                                  replace=False)\n",
    "test_shot_idx = [i for i in range(num_dis_shots) if i not in train_shot_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(rewards).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(sa_pairs)[:,train_shot_idx,:].reshape(-1, num_state+num_action)\n",
    "train_y = np.array(rewards)[:,train_shot_idx].reshape(-1, 1)\n",
    "test_X = np.array(sa_pairs)[:,test_shot_idx,:].reshape(-1, num_state+num_action)\n",
    "test_y = np.array(rewards)[:,test_shot_idx].reshape(-1, 1)\n",
    "print('Train: {}, {}'.format(train_X.shape, train_y.shape))\n",
    "print('Test: {}, {}'.format(test_X.shape, test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model and train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_mean = np.mean(train_X, axis=0)\n",
    "train_X_std = np.std(train_X, axis=0)\n",
    "train_y_mean = np.mean(train_y, axis=0)\n",
    "train_y_std = np.std(train_y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_train_X = (train_X - train_X_mean)/train_X_std\n",
    "normalized_train_y = (train_y - train_y_mean)/train_y_std\n",
    "print(normalized_train_X.shape, normalized_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_test_X = (test_X - train_X_mean)/train_X_std\n",
    "normalized_test_y = (test_y - train_y_mean)/train_y_std\n",
    "print(normalized_test_X.shape, normalized_test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = normalized_train_X.shape[0]\n",
    "num_test = normalized_test_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_train_idx = np.random.choice(num_train, size=100000)\n",
    "subset_train_X = train_X[rand_train_idx]\n",
    "subset_train_y = train_y[rand_train_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 2048\n",
    "num_layers = 5\n",
    "lr = 1e-3\n",
    "batch_size = 4096\n",
    "max_epochs = int(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_idx = 3\n",
    "cuda_device = \"cuda:{}\".format(gpu_idx)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(cuda_device if use_cuda else \"cpu\")\n",
    "print('Using device ', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betan_net = vanilla_nn(input_size=5, output_size=1,\n",
    "                      hidden_size=hidden_size, num_layers=num_layers,\n",
    "                      use_bn=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(betan_net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = betan_net.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionDataset(Dataset):\n",
    "    def __init__(self, X_arr, y_arr):\n",
    "        self.X = X_arr\n",
    "        self.y = y_arr.reshape(-1,1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FusionDataset(subset_train_X, subset_train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_test_idx = np.random.choice(num_test, size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "running_train_loss = []\n",
    "running_test_loss = []\n",
    "\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        batch_X, batch_y = batch_data\n",
    "        batch_X, batch_y = (batch_X.float()).to(device), (batch_y.float()).to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        batch_pred = betan_net(batch_X)\n",
    "        loss = criterion(batch_pred, batch_y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        \n",
    "    if epoch % 50 == 0:\n",
    "        print('Epoch {0} finished: loss {1:.4f}'.format(epoch, loss.item()))\n",
    "        running_train_loss.append(loss.item())\n",
    "    if epoch % 50 == 0:\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            rand_test_X = (torch.from_numpy(test_X[rand_test_idx]).float()).to(device)\n",
    "            rand_test_y = (torch.from_numpy(test_y[rand_test_idx]).float()).to(device)\n",
    "            test_loss = criterion(betan_net(rand_test_X), rand_test_y)\n",
    "            running_test_loss.append(test_loss.item())\n",
    "            print('Epoch {0}: rand test loss {1:.4f}'.format(epoch, test_loss.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(running_train_loss))*50, running_train_loss, label='train loss')\n",
    "plt.plot(np.arange(len(running_test_loss))*50, running_test_loss, label='test loss')\n",
    "plt.xlabel('Training epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betan_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_test_idx = np.random.choice(num_test, size=5000)\n",
    "rand_test_X = torch.from_numpy(test_X[rand_test_idx]).float().to(device)\n",
    "rand_test_y = torch.from_numpy(test_y[rand_test_idx]).float().to(device)\n",
    "betan_net(rand_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = torch.argsort(rand_test_X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_test_X[:,1][order].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(criterion(betan_net(rand_test_X), rand_test_y).item())\n",
    "with torch.no_grad():\n",
    "    plt.plot(rand_test_X[:,1][order].cpu(), rand_test_y[order].cpu(), label='label')\n",
    "    plt.plot(rand_test_X[:,1][order].cpu(), betan_net(rand_test_X)[order].cpu(), alpha = 0.5, label='prediction')\n",
    "    plt.xlabel('Starting betan')\n",
    "    plt.ylabel('Predicted betan')\n",
    "    plt.legend()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
